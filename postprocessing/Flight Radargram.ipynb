{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.signal as sp\n",
    "import processing as pr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from ruamel.yaml import YAML as ym\n",
    "import datetime\n",
    "import copy\n",
    "import re\n",
    "import scipy.fft\n",
    "import pickle\n",
    "\n",
    "# Use this for interactive graphs - nice for exploring\n",
    "#%matplotlib widget\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import mplcursors\n",
    "\n",
    "sys.path.append(\"../preprocessing\")\n",
    "from generate_chirp import generate_chirp\n",
    "\n",
    "# Widgets are only needed if you want to use the interactive plot at the end\n",
    "# Installation instructions: https://ipywidgets.readthedocs.io/en/latest/user_install.html\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8-28 Vatnajokull Day 1\n",
    "\n",
    "# prefix = \"../../drone/radar_data/20220828-vatnajokull-day1/20220828_055107\" # Flight 1\n",
    "# px4_logs = \"../../px4_logs/2022-08-28/12_40_43/12_40_43_\"\n",
    "\n",
    "# prefix = \"../../drone/radar_data/20220828-vatnajokull-day1/20220828_071157\" # Flight 2\n",
    "# px4_logs = \"../../px4_logs/2022-08-28/14_03_05/14_03_05_\"\n",
    "\n",
    "# 9-1 Vatnajokull Day 2\n",
    "# prefix = \"../../radar_data/20220901-vatnajokull-day2/20220901_085756\"\n",
    "# prefix = \"../../radar_data/20220901-vatnajokull-day2/20220901_090136\"\n",
    "# prefix = \"../../radar_data/20220901-vatnajokull-day2/20220901_090856\"\n",
    "# prefix = \"../../radar_data/20220901-vatnajokull-day2/20220901_091051\"\n",
    "# prefix = \"../../radar_data/20220901-vatnajokull-day2/20220901_091247\"\n",
    "# prefix = \"../../radar_data/20220901-vatnajokull-day2/20220901_091437\"\n",
    "# prefix = \"../../radar_data/20220901-vatnajokull-day2/20220901_091643\"\n",
    "\n",
    "# prefix = \"../../drone/radar_data/20220901-vatnajokull-day2/20220901_095129\" # Flight 1 -- possibly too aggressive PRF\n",
    "# px4_logs = \"../../px4_logs/ 2022-09-01/16_40_36/16_40_36_\"\n",
    "\n",
    "# prefix = \"../../radar_data/20220901-vatnajokull-day2/20220901_101053\" # 350 MHz center for anna\n",
    "# prefix = \"../../radar_data/20220901-vatnajokull-day2/20220901_102013\" # back to regular -- rect window now\n",
    "# prefix = \"../../radar_data/20220901-vatnajokull-day2/20220901_102245\"\n",
    "# prefix = \"../../radar_data/20220901-vatnajokull-day2/20220901_102720\"\n",
    "# prefix = \"../../radar_data/20220901-vatnajokull-day2/20220901_102935\"\n",
    "\n",
    "# prefix = \"../../drone/radar_data/20220901-vatnajokull-day2/20220901_105725\" # Flight 2\n",
    "# px4_logs = \"../../px4_logs/2022-09-01/17_43_54/17_43_54_\"\n",
    "\n",
    "# Vatnajokull Day 3 -- Wind, stuck in cabin\n",
    "\n",
    "# Vatnajokull Day 4\n",
    "\n",
    "# prefix = \"../../radar_data/20220903-vatnajokull-day4/20220903_030152\"\n",
    "# prefix = \"../../radar_data/20220903-vatnajokull-day4/20220903_033000\"\n",
    "\n",
    "# prefix = \"../../drone/radar_data/20220903-vatnajokull-day4/20220903_035332\" # Flight 1 - V2 to V1 transect\n",
    "# px4_logs = \"../../px4_logs/2022-09-03/10_40_26/10_40_26_\"\n",
    "\n",
    "# prefix = \"../../radar_data/20220903-vatnajokull-day4/20220903_045320\" # 350 mhz center, longer pulse\n",
    "# prefix = \"../../radar_data/20220903-vatnajokull-day4/20220903_045646\" # 3 db more tx power\n",
    "# prefix = \"../../radar_data/20220903-vatnajokull-day4/20220903_045933\" # another 3db\n",
    "# prefix = \"../../radar_data/20220903-vatnajokull-day4/20220903_062538\" # 2 more db\n",
    "# prefix = \"../../radar_data/20220903-vatnajokull-day4/20220903_062823\" # 150 us pulse\n",
    "# prefix = \"../../radar_data/20220903-vatnajokull-day4/20220903_063113\" # same thing, more pulses\n",
    "# prefix = \"../../radar_data/20220903-vatnajokull-day4/20220903_064218\" # final check\n",
    "\n",
    "prefix = \"../../drone/radar_data/20220903-vatnajokull-day4/20220903_070453\" # Flight 2\n",
    "px4_logs = \"../../px4_logs/2022-09-03/13_49_57/13_49_57_\"\n",
    "\n",
    "#prefix = \"../../radar_data/20220903-vatnajokull-day4/20220903_082804\" # 20 us pulse length, faster prf\n",
    "#prefix = \"../../radar_data/20220903-vatnajokull-day4/20220903_083111\" # faster prf\n",
    "#prefix = \"../../radar_data/20220903-vatnajokull-day4/20220903_083343\" # tried blackman window\n",
    "#prefix = \"../../radar_data/20220903-vatnajokull-day4/20220903_083526\" # back to rect\n",
    "#prefix = \"../../radar_data/20220903-vatnajokull-day4/20220903_083713\" # back to 390 mhz\n",
    "#prefix = \"../../radar_data/20220903-vatnajokull-day4/20220903_083842\" # blackman win\n",
    "#prefix = \"../../radar_data/20220903-vatnajokull-day4/20220903_084054\" # 3 db more\n",
    "#prefix = \"../../radar_data/20220903-vatnajokull-day4/20220903_084251\"\n",
    "#prefix = \"../../radar_data/20220903-vatnajokull-day4/20220903_084933\"\n",
    "#prefix = \"../../radar_data/20220903-vatnajokull-day4/20220903_085122\"\n",
    "#prefix = \"../../radar_data/20220903-vatnajokull-day4/20220903_085245\"\n",
    "#prefix = \"../../radar_data/20220903-vatnajokull-day4/20220903_085723\"\n",
    "\n",
    "# prefix = \"../../drone/radar_data/20220903-vatnajokull-day4/20220903_091901\" # Flight 3\n",
    "# px4_logs = \"../../px4_logs/2022-09-03/16_03_58/16_03_58_\"\n",
    "\n",
    "# Vatnajokull Day 5 -- SKF6\n",
    "\n",
    "#prefix = \"../../radar_data/20220904-vatnajokull-day5/20220904_032849\"\n",
    "\n",
    "# prefix = \"../../drone/radar_data/20220904-vatnajokull-day5/20220904_041423\" # Flight 1.5 (forgot to turn on radar for first one)\n",
    "# px4_logs = \"../../px4_logs/2022-09-04/11_04_34/11_04_34_\"\n",
    "\n",
    "# prefix = \"../../drone/radar_data/20220904-vatnajokull-day5/20220904_054559\" # Flight 2 (the long one)\n",
    "# px4_logs = \"../../px4_logs/2022-09-04/12_10_47/12_10_47_\"\n",
    "\n",
    "# Slakbreen 1\n",
    "\n",
    "#prefix = \"../../radar_data/20230313-slakbreen-day1/20230312_043805\" # Spot 1 -- New wings, 2x extensions\n",
    "#prefix = \"../../radar_data/20230313-slakbreen-day1/20230312_045810\" # Same thing, longer measurement\n",
    "#prefix = \"../../radar_data/20230313-slakbreen-day1/20230312_054339\" # Spot 2 -- New wings, 1x extensions\n",
    "#prefix = \"../../radar_data/20230313-slakbreen-day1/20230312_054746\" # Same thing, longer measurement\n",
    "#prefix = \"../../radar_data/20230313-slakbreen-day1/20230312_070350\" # Spot 3 -- Old (OG) wings, 1x extensions\n",
    "#prefix = \"../../radar_data/20230313-slakbreen-day1/20230312_070743\" # Same thing, longer measurement\n",
    "\n",
    "## Slakbreen 2\n",
    "\n",
    "# prefix = \"../../radar_data/20230314-slakbreen-day2/20230314_070258\" # Ground tests, tuning gain\n",
    "# prefix = \"../../radar_data/20230314-slakbreen-day2/20230314_070632\"\n",
    "# prefix = \"../../radar_data/20230314-slakbreen-day2/20230314_070854\"\n",
    "# prefix = \"../../radar_data/20230314-slakbreen-day2/20230314_071121\"\n",
    "\n",
    "# prefix = \"../../radar_data/20230314-slakbreen-day2/20230314_073911\" # Flight 1\n",
    "# px4_logs = \"../../px4_logs/2023-03-14/14_34_05/14_34_05_\"\n",
    "\n",
    "# prefix = \"../../radar_data/20230314-slakbreen-day2/20230314_080735\" # Flight 2\n",
    "# px4_logs = \"../../px4_logs/2023-03-14/14_59_01/14_59_01_\"\n",
    "\n",
    "# Slakbreen 3\n",
    "\n",
    "#prefix = \"../../radar_data/20230315-slakbreen-day3/20230315_061311\"\n",
    "#prefix = \"../../radar_data/20230315-slakbreen-day3/20230315_061607\"\n",
    "\n",
    "# prefix = \"../../radar_data/20230315-slakbreen-day3/20230315_064228\" # Flight 1\n",
    "# px4_logs = \"../../px4_logs/2023-03-15/13_35_40/13_35_40_\"\n",
    "\n",
    "#prefix = \"../../radar_data/20230315-slakbreen-day3/20230315_070941\" # Flight 2\n",
    "#px4_logs = \"../../px4_logs/2023-03-15/14_03_44/14_03_44_\"\n",
    "\n",
    "# prefix = \"../../radar_data/20230315-slakbreen-day3/20230315_074655\" # Flight 3\n",
    "# px4_logs = \"../../px4_logs/2023-03-15/14_38_58/14_38_58_\"\n",
    "\n",
    "\n",
    "# Slakbreen 4\n",
    "\n",
    "# prefix = \"../../radar_data/20230316-slakbreen-day4/20230316_071250\"\n",
    "# px4_logs = \"../../px4_logs/2023-03-16/13_58_18/13_58_18_\"\n",
    "\n",
    "# Slakbreen 5\n",
    "\n",
    "# prefix = \"../../radar_data/20230317-slakbreen-day5/20230317_033041\" # flight 1 (2x liion, 2x wing ext)\n",
    "# px4_logs = \"../../px4_logs/2023-03-17/10_20_31/10_20_31_\"\n",
    "\n",
    "prefix = \"../../radar_data/20230317-slakbreen-day5/20230317_042115\" # flight 2 (2x liion, 1x wing ext)\n",
    "px4_logs = \"../../px4_logs/2023-03-17/10_58_17/10_58_17_\"\n",
    "\n",
    "#prefix = \"../../radar_data/20230317-slakbreen-day5/20230317_061000\" # flight 3 (2x liion, 1x wing ext)\n",
    "#px4_logs = \"../../px4_logs/2023-03-17/12_47_41/12_47_41_\"\n",
    "\n",
    "\n",
    "#px4_logs = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load data_bench\n",
    "# px4_logs = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_file = prefix + \"_config.yaml\"\n",
    "bin_file = prefix + \"_rx_samps.bin\"\n",
    "log_file = prefix + \"_uhd_stdout.log\"\n",
    "\n",
    "# For PX4 logs: They must be converted to a set of CSV files with pyulog\n",
    "# For example: `ulog2csv 17_39_45.ulg -o 17_39_45/`\n",
    "\n",
    "# Thomas's system at 56 MHz sample rate - zero_sample_idx = 159\n",
    "zero_sample_idx = 159"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Constants\n",
    "yaml = ym()\n",
    "with open(yaml_file) as stream:\n",
    "    config = yaml.load(stream)\n",
    "    sample_rate = config[\"PLOT\"][\"sample_rate\"]    # Hertz\n",
    "    sig_speed = config[\"PLOT\"][\"sig_speed\"] / np.sqrt(3.17) ## ICE\n",
    "    \n",
    "    rx_len_samples = int(config['CHIRP']['rx_duration'] * config['GENERATE']['sample_rate'])\n",
    "    \n",
    "rx_samps = bin_file\n",
    "\n",
    "config_blackman_window = copy.deepcopy(config)\n",
    "config_blackman_window['GENERATE']['window'] = 'blackman'\n",
    "\n",
    "# Read and plot RX/TX\n",
    "# This cell loads all of the data - it can take a while with a large file. You don't need to re-run this cell if you only change n_stack\n",
    "_, tx_sig = generate_chirp(config)\n",
    "_, tx_sig_blackman_window = generate_chirp(config_blackman_window)\n",
    "pr.plotChirpVsTime(tx_sig, 'Transmitted Chirp', sample_rate)\n",
    "print(f\"len(tx_sig): {len(tx_sig)}\")\n",
    "\n",
    "t0 = datetime.datetime.now()\n",
    "\n",
    "max_chunk_size_samples = int(2e8)\n",
    "max_seconds_to_load = 60*100\n",
    "load_start_seconds = 0\n",
    "\n",
    "max_file_size_bytes = rx_len_samples*int(1/config['CHIRP']['pulse_rep_int'])*8*max_seconds_to_load\n",
    "load_start_bytes = rx_len_samples*int(1/config['CHIRP']['pulse_rep_int'])*8*load_start_seconds\n",
    "\n",
    "file_size_bytes = os.path.getsize(rx_samps) - load_start_bytes\n",
    "if file_size_bytes > max_file_size_bytes:\n",
    "    print(f\"WARNING: File is {file_size_bytes/(2**30):.2f} GB ({file_size_bytes / (rx_len_samples*int(1/config['CHIRP']['pulse_rep_int'])*2):.2f} seconds). Only loading the first {max_seconds_to_load} seconds.\")\n",
    "    file_size_bytes = max_file_size_bytes\n",
    "\n",
    "rx_sig = np.zeros((file_size_bytes//8,), dtype=np.csingle)\n",
    "for start_offset in np.arange(0, file_size_bytes, max_chunk_size_samples*8, dtype=np.int64):\n",
    "    if start_offset + max_chunk_size_samples*8 > file_size_bytes:\n",
    "        rx_sig[(start_offset//8):] = pr.extractSig(rx_samps, count=(file_size_bytes-start_offset)//4, offset=load_start_bytes+start_offset)\n",
    "    else:\n",
    "        rx_sig[(start_offset//8):((start_offset//8)+(max_chunk_size_samples))] = pr.extractSig(rx_samps, count=max_chunk_size_samples*2, offset=load_start_bytes+start_offset)\n",
    "\n",
    "print(datetime.datetime.now() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reshape data\n",
    "\n",
    "n_rxs = len(rx_sig) // rx_len_samples\n",
    "rx_sig_reshaped = np.transpose(np.reshape(rx_sig, (n_rxs, rx_len_samples), order='C'))\n",
    "errors_removed = False # Keep track of if the cell removing errors from rx_sig_reshaped has already been run\n",
    "\n",
    "print(f\"len(rx_sig): {len(rx_sig)}\")\n",
    "print(f\"n_rxs: {n_rxs}\")\n",
    "print(f\"rx_sig shape: {np.shape(rx_sig)}\")\n",
    "print(f\"rx_sig_reshaped shape: {np.shape(rx_sig_reshaped)}\")\n",
    "\n",
    "# Extract log information about errors and start timestamp\n",
    "\n",
    "errors = None\n",
    "start_timestamp = None\n",
    "\n",
    "if os.path.exists(log_file):\n",
    "    errors = {}\n",
    "    \n",
    "    log_f = open(log_file, 'r')\n",
    "    log = log_f.readlines()\n",
    "    \n",
    "    for idx, line in enumerate(log):\n",
    "        if \"Receiver error:\" in line:\n",
    "            error_code = re.search(\"(?:Receiver error: )([\\w_]+)\", line).groups()[0]\n",
    "            old_style_regex_serach = re.search(\"(?:Scheduling chirp )([\\d]+)\", log[idx-1])\n",
    "            if old_style_regex_serach is not None:\n",
    "                chirp_idx = int(re.search(\"(?:Scheduling chirp )([\\d]+)\", log[idx-1]).groups()[0])\n",
    "            else:\n",
    "                chirp_idx = int(re.search(\"(?:Chirp )([\\d]+)\", line).groups()[0])\n",
    "            errors[chirp_idx] = error_code\n",
    "            if error_code != \"ERROR_CODE_LATE_COMMAND\":\n",
    "                print(f\"WARNING: Uncommon error in the log: {error_code} (on chirp {chirp_idx})\")\n",
    "                print(f\"Full message: {line}\")\n",
    "        if (\"[START]\" in line) or (\"Scheduling chirp 0 RX\" in line):\n",
    "            start_timestamp = float(re.search(\"(?:\\[)([\\d]+\\.[\\d]+)\", line).groups()[0])\n",
    "else:\n",
    "    print(f\"WARNING: No log file found. This is fine, but checks for error codes will be disabled.\")\n",
    "    print(f\"(Looking for a log file in: {log_file})\")\n",
    "\n",
    "# Handle errors\n",
    "\n",
    "# Choose what to do with chirps with a reported error (usually ERROR_CODE_LATE_COMMAND)\n",
    "# Options are:\n",
    "# None - do nothing\n",
    "# 'zeros' - replace with zeros\n",
    "# 'remove' - remove them from the rx_sig_reshaped array\n",
    "error_behavior = None\n",
    "\n",
    "if errors is None:\n",
    "    if error_behavior is not None:\n",
    "        print(f\"WARNING: Requested doing something with errors but no log file was loaded. Defaulting to doing nothing.\")\n",
    "elif error_behavior == 'zeros':\n",
    "    error_idxs = np.array(list(errors.keys()))\n",
    "    rx_sig_reshaped[:,error_idxs] = 0\n",
    "elif error_behavior == 'remove':\n",
    "    if errors_removed:\n",
    "        print(f\"WARNING: Error chirps already removed since rx_sig_reshaped created. Not doing again.\")\n",
    "    else:\n",
    "        error_idxs = np.array(list(errors.keys()))\n",
    "        all_idxs = np.arange(rx_sig_reshaped.shape[1])\n",
    "        keep_idxs = [x for x in all_idxs if x not in error_idxs]\n",
    "\n",
    "        rx_sig_reshaped = rx_sig_reshaped[:, keep_idxs]\n",
    "        n_rxs = len(keep_idxs)\n",
    "        errors_removed = True\n",
    "    \n",
    "print(f\"n_rxs: {n_rxs}\")\n",
    "print(f\"rx_sig_reshaped shape: {np.shape(rx_sig_reshaped)}\")\n",
    "print(f\"Extracted start timestamp: {start_timestamp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_time = np.linspace(0, config['CHIRP']['pulse_rep_int']*config['CHIRP']['num_presums']*n_rxs, np.shape(rx_sig_reshaped)[1])\n",
    "\n",
    "for idx in errors:\n",
    "    slow_time[idx+1:] += config['CHIRP']['pulse_rep_int'] * 3\n",
    "\n",
    "# TODO: Should play with this more to see if it correctly accounts for drift to to errors\n",
    "\n",
    "#plt.plot(np.diff(slow_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chirp_idx = 19000\n",
    "print(slow_time[chirp_idx])\n",
    "fig, axs = pr.plotChirpVsTime(rx_sig_reshaped[:,chirp_idx], 'Recieved Chirp', sample_rate)\n",
    "axs[0].set_ylim(-1,1)\n",
    "axs[1].set_ylim(-1,1)\n",
    "axs[0].text(0, 1.1, prefix.split(\"/\")[-1] + \"\\n\" + f\"chirp_idx = {chirp_idx}\", horizontalalignment='left', verticalalignment='center', transform=axs[0].transAxes)\n",
    "plt.savefig(prefix + \"_rx_chirp.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = rx_sig_reshaped[:, 0:19316:100]\n",
    "test = test.transpose().flatten()\n",
    "\n",
    "np.all(test[rx_len_samples*100:rx_len_samples*101] == rx_sig_reshaped[:,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rx_spectrum(input_rx_sig_reshaped = rx_sig_reshaped, subsample=1, start_time_s=0, duration_s=-1, figsize=None, vmin=None, vmax=None, x_axis_label='Time [s]'):\n",
    "\n",
    "    if duration_s < 0:\n",
    "        duration_s = np.max(slow_time) - start_time_s\n",
    "\n",
    "    start_idx = np.argmin(np.abs(slow_time - start_time_s))\n",
    "    end_idx = np.argmin(np.abs(slow_time - (start_time_s + duration_s)))\n",
    "    actual_duration_s = slow_time[end_idx] - slow_time[start_idx]\n",
    "    \n",
    "    slow_time_plot = slow_time[np.arange(start_idx, end_idx+1, subsample)]\n",
    "\n",
    "    rx_sig_cropped = input_rx_sig_reshaped[:, start_idx:end_idx:subsample]\n",
    "    \n",
    "    print(start_idx)\n",
    "    print(end_idx)\n",
    "    print(np.shape(rx_sig_cropped))\n",
    "    print(np.shape(slow_time_plot))\n",
    "    \n",
    "    rx_sig_tmp = rx_sig_cropped.transpose().flatten()\n",
    "    \n",
    "    f, t, Sxx = scipy.signal.spectrogram(rx_sig_tmp, fs = sample_rate, nperseg=rx_len_samples, noverlap=0, mode='magnitude', return_onesided=False)\n",
    "    \n",
    "    if figsize is None:\n",
    "        figsize = (duration_s/10, 5)\n",
    "            \n",
    "    fig, ax = plt.subplots(1,1, figsize=figsize, facecolor='white')    \n",
    "\n",
    "    p = ax.pcolormesh(t, scipy.fft.fftshift(f)/1e6, 10*np.log10(scipy.fft.fftshift(Sxx, axes=0)), shading='gouraud')#, cmap='inferno', vmin=vmin, vmax=vmax)\n",
    "    clb = fig.colorbar(p, ax=ax)\n",
    "    clb.set_label('Power Spectral Density [dB/Hz]')\n",
    "    #ax.set_xlabel('Time [s]')\n",
    "    ax.set_ylabel('Frequency [MHz]')\n",
    "\n",
    "    ax.text(0, 1.05, prefix.split(\"/\")[-1] + \"\\n\" + f\"subsample = {subsample}\", horizontalalignment='left', verticalalignment='center', transform=ax.transAxes)\n",
    "\n",
    "    for item in ([ax.title, ax.xaxis.label, ax.yaxis.label, clb.ax.yaxis.label] +\n",
    "                ax.get_xticklabels() + ax.get_yticklabels() + clb.ax.get_yticklabels()): #ax.get_legend().get_texts()\n",
    "        item.set_fontsize(18)\n",
    "        item.set_fontfamily('sans-serif')\n",
    "        \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "#plot_rx_spectrum(duration_s=500, subsample=100, figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, _ = plot_radargram(n_stack=20, start_time_s=100, duration_s=10, upsampling=1, figsize=(15, 5), vmin=-50, vmax=-0, ylims=(150, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(rx_sig_reshaped))\n",
    "\n",
    "tx_sig_padded = np.zeros((np.shape(rx_sig_reshaped)[0],), dtype=np.complex64)\n",
    "tx_sig_padded[0:len(tx_sig)] = tx_sig\n",
    "#tx_sig_padded[3:len(tx_sig)+3] += 0.5*tx_sig\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(np.real(tx_sig))\n",
    "# ax.plot(np.real(tx_sig_padded))\n",
    "# ax.plot(np.real(rx_sig_reshaped[:,0]))\n",
    "\n",
    "tx_sig_padded\n",
    "\n",
    "tx_sig_duplicated = np.transpose(np.tile(np.transpose(tx_sig_padded), (2000,1)))\n",
    "print(np.shape(tx_sig_duplicated))\n",
    "\n",
    "plot_rx_spectrum(input_rx_sig_reshaped = tx_sig_duplicated, duration_s=1, subsample=1, figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_radargram(n_stack=15, start_time_s=0, duration_s=-1, upsampling=1, figsize=None, vmin=-70, vmax=-40, ylims=(65, 15), surface_dist=None, x_axis=None, x_axis_label='Time [s]'):\n",
    "\n",
    "    if duration_s < 0:\n",
    "        duration_s = np.max(slow_time) - start_time_s\n",
    "\n",
    "    start_idx = np.argmin(np.abs(slow_time - start_time_s))\n",
    "    end_idx = np.argmin(np.abs(slow_time - (start_time_s + duration_s)))\n",
    "    actual_duration_s = slow_time[end_idx] - slow_time[start_idx]\n",
    "\n",
    "    rx_sig_cropped = rx_sig_reshaped[:, start_idx:end_idx]\n",
    "\n",
    "    corr_sig = tx_sig_blackman_window\n",
    "\n",
    "    if upsampling > 1:\n",
    "        corr_sig = scipy.signal.resample_poly(corr_sig, upsampling, 1)\n",
    "\n",
    "    xcorr_results = np.zeros((((rx_len_samples*upsampling)-len(corr_sig))+1, np.shape(rx_sig_cropped)[1]//n_stack), dtype=np.csingle)\n",
    "\n",
    "    if surface_dist is not None:\n",
    "        surface_dist_plot = surface_dist[np.arange(start_idx, end_idx-n_stack, n_stack)]\n",
    "    \n",
    "    slow_time_plot = slow_time[np.arange(start_idx, end_idx-n_stack+1, n_stack)]\n",
    "    if x_axis is None:\n",
    "        x_axis_plot = slow_time_plot\n",
    "    else:\n",
    "        x_axis_plot = x_axis[np.arange(start_idx, end_idx-n_stack+1, n_stack)]\n",
    "    \n",
    "    distance_to_reflector = np.linspace(0, np.shape(xcorr_results)[0]/(sample_rate*upsampling), np.shape(xcorr_results)[0]) * sig_speed / 2\n",
    "    distance_to_reflector = distance_to_reflector - distance_to_reflector[zero_sample_idx*upsampling]\n",
    "\n",
    "    for res_idx in range(np.shape(xcorr_results)[1]):\n",
    "        stacked = np.mean(rx_sig_cropped[:,res_idx*n_stack:(res_idx+1)*n_stack], axis=1)\n",
    "        if upsampling > 1:\n",
    "            stacked = scipy.signal.resample_poly(stacked, upsampling, 1)\n",
    "\n",
    "        if surface_dist is not None:\n",
    "            surf_idx_offset = np.argmin(np.abs(distance_to_reflector - surface_dist_plot[res_idx])) - np.argmin(np.abs(distance_to_reflector))\n",
    "            xcorr_results[:-surf_idx_offset, res_idx] = sp.correlate(stacked, corr_sig, mode='valid', method='auto')[surf_idx_offset:] / np.sum(np.abs(corr_sig)**2)\n",
    "        else:\n",
    "            xcorr_results[:, res_idx] = sp.correlate(stacked, corr_sig, mode='valid', method='auto') / np.sum(np.abs(corr_sig)**2)\n",
    "        \n",
    "    if figsize is None:\n",
    "        figsize = (duration_s/10, 5)\n",
    "            \n",
    "    fig, ax = plt.subplots(1,1, figsize=figsize, facecolor='white')\n",
    "\n",
    "    \n",
    "\n",
    "    return_power = 20*np.log10(np.abs(xcorr_results))\n",
    "    p = ax.pcolormesh(x_axis_plot, distance_to_reflector, return_power, shading='auto', cmap='inferno', vmin=vmin, vmax=vmax)\n",
    "    clb = fig.colorbar(p, ax=ax)\n",
    "    clb.set_label('Power [dB]')\n",
    "    ax.set_xlabel(x_axis_label)\n",
    "    ax.set_ylabel('Distance to reflector [m]')\n",
    "\n",
    "    ax.set_ylim(ylims[0], ylims[1])\n",
    "    #ax.set_xlim(start_time_s,start_time_s+duration_s)\n",
    "    ax.set_xlim(np.min(x_axis_plot), np.max(x_axis_plot))\n",
    "\n",
    "    ax.text(0, 1.05, prefix.split(\"/\")[-1] + \"\\n\" + f\"n_stack = {n_stack}\", horizontalalignment='left', verticalalignment='center', transform=ax.transAxes)\n",
    "\n",
    "    for item in ([ax.title, ax.xaxis.label, ax.yaxis.label, clb.ax.yaxis.label] +\n",
    "                ax.get_xticklabels() + ax.get_yticklabels() + clb.ax.get_yticklabels()): #ax.get_legend().get_texts()\n",
    "        item.set_fontsize(18)\n",
    "        item.set_fontfamily('sans-serif')\n",
    "        \n",
    "    fig.tight_layout()\n",
    "\n",
    "    return fig, ax, {'slow_time': slow_time_plot, 'distance_to_reflector': distance_to_reflector, 'return_power': return_power}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, _ = plot_radargram(n_stack=20, start_time_s=0, duration_s=100, upsampling=1, figsize=(15, 5), vmin=-90, vmax=-40, ylims=(300, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax, _ = plot_radargram(n_stack=20, start_time_s=0, duration_s=-1, upsampling=1, figsize=(15, 5), vmin=-90, vmax=-35, ylims=(150, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must enable widgets (see imports block) for this to work\n",
    "\n",
    "def plot_timestep(start_chirp_idx, n_stack):\n",
    "    \n",
    "    stacked = np.mean(rx_sig_reshaped[:,start_chirp_idx:start_chirp_idx+n_stack], axis=1)\n",
    "    \n",
    "    xcorr_res_tmp = sp.correlate(stacked, tx_sig_blackman_window, mode='valid', method='direct')\n",
    "    \n",
    "    slow_time = np.linspace(0,config['CHIRP']['pulse_rep_int']*config['CHIRP']['num_presums']*n_rxs, np.shape(rx_sig_reshaped)[1])\n",
    "    \n",
    "    distance_to_reflector = np.linspace(0, np.shape(xcorr_res_tmp)[0]/sample_rate, np.shape(xcorr_res_tmp)[0]) * sig_speed / 2\n",
    "    distance_to_reflector = distance_to_reflector - distance_to_reflector[zero_sample_idx]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10,5), facecolor='white')\n",
    "    line = ax.plot(distance_to_reflector, 20*np.log10(np.abs(xcorr_res_tmp)), label=\"Data\")\n",
    "    mplcursors.cursor(line)\n",
    "    #ax.set_ylim(0,100)\n",
    "    ax.set_ylim(-40,80)\n",
    "    ax.set_ylim(-20,40)\n",
    "    #ax.set_ylim(-20,80)\n",
    "    ax.set_xlim(-20, 120)\n",
    "    #ax.set_xlim(-20, 700)\n",
    "    ax.set_xlim(-200,600)\n",
    "    ax.set_xlim(-10,250)\n",
    "    #ax.set_xlim(-500,500)\n",
    "    ax.set_xlabel('Distance [m]')\n",
    "    ax.set_ylabel('Power [dB]')\n",
    "    ax.set_title(f't = {slow_time[start_chirp_idx]:.2f} s')\n",
    "    ax.grid()\n",
    "    \n",
    "    direct_path_time_offset = distance_to_reflector[np.argmax(np.abs(xcorr_res_tmp))]\n",
    "    \n",
    "    #ax.plot(distance_to_reflector_autocorr + direct_path_time_offset, 20*np.log10(np.abs(tx_sig_rx_envelope_corr)), label=\"TX sig w/ RX envelope scaling corr\", alpha=0.2)\n",
    "    #ax.plot(-1*distance_to_reflector + 2*direct_path_time_offset, 20*np.log10(np.abs(xcorr_res_tmp)), label=\"Data (distance flipped)\", alpha=0.2)\n",
    "    \n",
    "    # Theoretical TX sig autocorr\n",
    "    tx_sig_autocorr = sp.correlate(tx_sig, tx_sig, mode='same', method='auto')\n",
    "    tx_sig_autocorr_db = 20*np.log10(np.abs(tx_sig_autocorr))\n",
    "\n",
    "    distance_to_reflector_autocorr = np.linspace(0, len(tx_sig_autocorr)/sample_rate, len(tx_sig_autocorr)) * sig_speed / 2\n",
    "    distance_to_reflector_autocorr = distance_to_reflector_autocorr - distance_to_reflector_autocorr[len(tx_sig_autocorr)//2]\n",
    "\n",
    "    #ax.plot(distance_to_reflector_autocorr, tx_sig_autocorr_db - np.max(tx_sig_autocorr_db) + np.max(20*np.log10(np.abs(xcorr_res_tmp))), label=\"Theoretical TX sig autocorr\")\n",
    "    \n",
    "    # rx_sig_autocorr_peak_idx = np.argmax(np.abs(rx_sig_autocorr))\n",
    "    # xcorr_peak_idx = np.argmax(np.abs(xcorr_res_tmp))\n",
    "    # print(xcorr_peak_idx)\n",
    "    # rx_sig_autocorr_aligned = rx_sig_autocorr[rx_sig_autocorr_peak_idx - xcorr_peak_idx : rx_sig_autocorr_peak_idx + (len(xcorr_res_tmp) - xcorr_peak_idx)]\n",
    "    # rx_sig_autocorr_aligned = rx_sig_autocorr_aligned  * (np.max(np.abs(xcorr_res_tmp)) / np.max(np.abs(rx_sig_autocorr_aligned))) # scale peak\n",
    "\n",
    "    #ax.plot(distance_to_reflector, 20*np.log10(rx_sig_autocorr_aligned))\n",
    "    \n",
    "    #ax.plot(distance_to_reflector, 20*np.log10(np.maximum(np.abs(xcorr_res_tmp) - 0.95*np.abs(rx_sig_autocorr_aligned), 0.1)))\n",
    "    direct_path_sample_idx = np.argmax(np.abs(xcorr_res_tmp))\n",
    "    xcorr_subtracted = (np.abs(xcorr_res_tmp))\n",
    "    xcorr_subtracted[direct_path_sample_idx:2*direct_path_sample_idx] -= (np.abs(xcorr_res_tmp[direct_path_sample_idx:0:-1]))\n",
    "\n",
    "    #np.abs(xcorr_res_tmp[:-(direct_path_sample_offset)]) - \n",
    "    #ax.plot(distance_to_reflector, 20*np.log10(np.abs(xcorr_subtracted)))\n",
    "    \n",
    "    #ax.plot(distance_to_reflector_autocorr + direct_path_time_offset, 20*np.log10(np.abs(rx_sig_autocorr_mean)))\n",
    "    \n",
    "    #ax.legend()\n",
    "    \n",
    "    ax.text(0, 1.05, prefix.split(\"/\")[-1] + \"\\n\" + f\"n_stack = {n_stack}, start_chirp_idx = {start_chirp_idx}\", horizontalalignment='left', verticalalignment='center', transform=ax.transAxes)\n",
    "    \n",
    "    return fig, ax\n",
    "    \n",
    "widgets.interact(plot_timestep,\n",
    "                 start_chirp_idx=widgets.IntSlider(min=0, max=np.shape(rx_sig_reshaped)[1]-1, step=1, value=0),\n",
    "                 n_stack=widgets.IntSlider(min=1, max=100, step=1, value=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SNR Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "reference_range = [40, 60]\n",
    "surface_range = [20, 30]\n",
    "\n",
    "verbose = False\n",
    "\n",
    "n_stacks = np.sort(list(set(np.logspace(np.log10(1), np.log10(500), 20).astype(int)))) #np.arange(1, 150, 5)\n",
    "#n_stacks = np.array([1, 5, 10, 30, 100])\n",
    "sig, noise = np.zeros_like(n_stacks, dtype=float), np.zeros_like(n_stacks, dtype=float)\n",
    "\n",
    "for idx, n_stack in enumerate(n_stacks):\n",
    "    fig, _, radargram_data = plot_radargram(n_stack=n_stack, start_time_s=0, duration_s=-1, upsampling=1, figsize=(15, 5), vmin=-100, vmax=-35, ylims=(60, -10))\n",
    "    #fig, _, radargram_data = phase_align_test(n_stack=n_stack, start_time_s=0, duration_s=-1, upsampling=1, figsize=(15, 5), vmin=-100, vmax=-35, ylims=(60, -10))\n",
    "    \n",
    "    fig.savefig(f\"figures/tmp_gif/{prefix.split('/')[-1]}_nstack_{n_stack:03d}.png\")\n",
    "    \n",
    "#     fig, ax = plt.subplots(figsize=(15,5), facecolor='white')\n",
    "#     ax.plot(radargram_data['distance_to_reflector'], radargram_data['return_power'][:, 0])\n",
    "#     ax.set_xlim(-10,60)\n",
    "#     ax.set_ylim(-100,-30)\n",
    "#     ax.grid()\n",
    "#     ax.set_xlabel('Distance to reflector [m]')\n",
    "#     ax.set_ylabel('Return power [dB]')\n",
    "#     ax.set_title(f\"[{prefix.split('/')[-1]}] n_stack = {n_stack}\")\n",
    "    \n",
    "#     fig.savefig(f\"figures/tmp_gif/{prefix.split('/')[-1]}_1d_nstack_{n_stack:03d}.png\")\n",
    "    \n",
    "    surface_idxs_mask = (radargram_data['distance_to_reflector'] <= surface_range[1]) & (radargram_data['distance_to_reflector'] >= surface_range[0])\n",
    "    noise_reference_idxs_mask = (radargram_data['distance_to_reflector'] <= reference_range[1]) & (radargram_data['distance_to_reflector'] >= reference_range[0])\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Using {reference_range[0]} m to {reference_range[1]} m as the noise floor. ({np.sum(noise_reference_idxs_mask)} range bins)\")\n",
    "        print(f\"Searching for surface peak from {surface_range[0]} m to {surface_range[1]} m as the noise floor. ({np.sum(surface_idxs_mask)} range bins)\")\n",
    "        print(f\"Taking median values over {len(radargram_data['slow_time'])} along-track samples\")\n",
    "\n",
    "    surface_peaks_db = np.zeros_like(radargram_data['slow_time'])\n",
    "    noise_means_db = np.zeros_like(radargram_data['slow_time'])\n",
    "\n",
    "    for time_idx in range(len(radargram_data['slow_time'])):\n",
    "        pwr = radargram_data['return_power'][:, time_idx]\n",
    "        surface_peaks_db[time_idx] = np.max(pwr[surface_idxs_mask])\n",
    "        noise_reference_values_db = pwr[noise_reference_idxs_mask]\n",
    "        noise_reference_values_linear = 10**(noise_reference_values_db / 20)\n",
    "        noise_means_db[time_idx] = 20 * np.log10(np.mean(noise_reference_values_linear))\n",
    "        \n",
    "    sig[idx] = np.median(surface_peaks_db)\n",
    "    noise[idx] = np.median(noise_means_db)\n",
    "    \n",
    "    print(f\"[n_stack = {n_stack}] \\t\", end=\"\")\n",
    "    print(f\"Median surface peak: {np.median(surface_peaks_db):.2f} dB \\tMedian noise: {np.median(noise_means_db):.2f} dB\", end=\"\")\n",
    "    print(f\" \\tSNR: {np.median(surface_peaks_db) - np.median(noise_means_db):.2f} dB\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,1, figsize=(15, 10), facecolor='white')\n",
    "\n",
    "axs[0].scatter(n_stacks, sig, label='Signal [dB]')\n",
    "axs[0].scatter(n_stacks, noise, label='Noise [dB]')\n",
    "axs[0].legend()\n",
    "axs[0].set_ylabel('Power [dB]')\n",
    "axs[0].set_title('Signal and noise estimated power [dB]')\n",
    "axs[0].grid()\n",
    "axs[0].set_xlabel('n_stack')\n",
    "\n",
    "snrs = sig - noise\n",
    "snr_lin = 10**(snrs / 20)\n",
    "\n",
    "assert n_stacks[0] == 1\n",
    "\n",
    "axs[1].scatter(n_stacks, snr_lin, c='red', label='Estimted from data')\n",
    "axs[1].plot(n_stacks, n_stacks*snr_lin[0], label='Theoretical coherent summation')\n",
    "axs[1].plot(n_stacks, np.sqrt(n_stacks)*snr_lin[0], label='Theoretical incoherent summation')\n",
    "axs[1].set_ylabel('SNR [dimensionless, linear scale]')\n",
    "axs[1].set_title('Linear scale SNR')\n",
    "axs[1].legend()\n",
    "axs[1].grid()\n",
    "axs[1].set_xlabel('n_stack')\n",
    "axs[1].set_ylim(0, 50)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase_align_test(n_stack=15, start_time_s=0, duration_s=-1, upsampling=1, figsize=None, vmin=-70, vmax=-40, ylims=(65, 15), surface_dist=None, x_axis=None, x_axis_label='Time [s]', phase_align=True):\n",
    "\n",
    "    if duration_s < 0:\n",
    "        duration_s = np.max(slow_time) - start_time_s\n",
    "\n",
    "    start_idx = np.argmin(np.abs(slow_time - start_time_s))\n",
    "    end_idx = np.argmin(np.abs(slow_time - (start_time_s + duration_s)))\n",
    "    actual_duration_s = slow_time[end_idx] - slow_time[start_idx]\n",
    "\n",
    "    rx_sig_cropped = rx_sig_reshaped[:, start_idx:end_idx]\n",
    "\n",
    "    corr_sig = tx_sig_blackman_window\n",
    "\n",
    "    if upsampling > 1:\n",
    "        corr_sig = scipy.signal.resample_poly(corr_sig, upsampling, 1)\n",
    "\n",
    "    xcorr_results = np.zeros((((rx_len_samples*upsampling)-len(corr_sig))+1, np.shape(rx_sig_cropped)[1]), dtype=np.csingle)\n",
    "    xcorr_results_stacked = np.zeros((((rx_len_samples*upsampling)-len(corr_sig))+1, np.shape(rx_sig_cropped)[1]//n_stack), dtype=np.csingle)\n",
    "\n",
    "    if surface_dist is not None:\n",
    "        surface_dist_plot = surface_dist[np.arange(start_idx, end_idx-n_stack, n_stack)]\n",
    "    \n",
    "    slow_time_plot = slow_time[np.arange(start_idx, end_idx-n_stack+1, n_stack)]\n",
    "    if x_axis is None:\n",
    "        x_axis_plot = slow_time_plot\n",
    "    else:\n",
    "        x_axis_plot = x_axis[np.arange(start_idx, end_idx-n_stack+1, n_stack)]\n",
    "    \n",
    "    distance_to_reflector = np.linspace(0, np.shape(xcorr_results)[0]/(sample_rate*upsampling), np.shape(xcorr_results)[0]) * sig_speed / 2\n",
    "    distance_to_reflector = distance_to_reflector - distance_to_reflector[zero_sample_idx*upsampling]\n",
    "\n",
    "    for res_idx in range(np.shape(rx_sig_cropped)[1]):\n",
    "        #stacked = np.mean(rx_sig_cropped[:,res_idx*n_stack:(res_idx+1)*n_stack], axis=1)\n",
    "        trace = rx_sig_cropped[:,res_idx]\n",
    "        \n",
    "        if upsampling > 1:\n",
    "            trace = scipy.signal.resample_poly(trace, upsampling, 1)\n",
    "\n",
    "        xcorr_results[:, res_idx] = sp.correlate(trace, corr_sig, mode='valid', method='auto') / np.sum(np.abs(corr_sig)**2)\n",
    "        \n",
    "    if phase_align:\n",
    "        peaks_direct = np.argmax(np.abs(xcorr_results), axis=0)\n",
    "        direct = [xcorr_results[x,idx] for idx, x in enumerate(peaks_direct)]\n",
    "        xcorr_aligned = np.array([xcorr_results[:,idx] * np.exp(-1j * np.angle(direct[idx])) for idx in range(np.shape(rx_sig_cropped)[1])])\n",
    "        xcorr_results = np.transpose(xcorr_aligned)\n",
    "        \n",
    "    for res_idx in range(np.shape(xcorr_results_stacked)[1]):\n",
    "        xcorr_results_stacked[:, res_idx] = np.mean(xcorr_results[:,res_idx*n_stack:(res_idx+1)*n_stack], axis=1)\n",
    "    \n",
    "    \n",
    "    # TODO: Support surf_dist again -- after all other processing\n",
    "    \n",
    "    if figsize is None:\n",
    "        figsize = (duration_s/10, 5)\n",
    "            \n",
    "    fig, ax = plt.subplots(1,1, figsize=figsize, facecolor='white')\n",
    "\n",
    "    \n",
    "\n",
    "    return_power = 20*np.log10(np.abs(xcorr_results_stacked))\n",
    "    p = ax.pcolormesh(x_axis_plot, distance_to_reflector, return_power, shading='auto', cmap='inferno', vmin=vmin, vmax=vmax)\n",
    "    clb = fig.colorbar(p, ax=ax)\n",
    "    clb.set_label('Power [dB]')\n",
    "    ax.set_xlabel(x_axis_label)\n",
    "    ax.set_ylabel('Distance to reflector [m]')\n",
    "\n",
    "    ax.set_ylim(ylims[0], ylims[1])\n",
    "    #ax.set_xlim(start_time_s,start_time_s+duration_s)\n",
    "    ax.set_xlim(np.min(x_axis_plot), np.max(x_axis_plot))\n",
    "\n",
    "    ax.text(0, 1.05, prefix.split(\"/\")[-1] + \"\\n\" + f\"n_stack = {n_stack}\", horizontalalignment='left', verticalalignment='center', transform=ax.transAxes)\n",
    "\n",
    "    for item in ([ax.title, ax.xaxis.label, ax.yaxis.label, clb.ax.yaxis.label] +\n",
    "                ax.get_xticklabels() + ax.get_yticklabels() + clb.ax.get_yticklabels()): #ax.get_legend().get_texts()\n",
    "        item.set_fontsize(18)\n",
    "        item.set_fontfamily('sans-serif')\n",
    "        \n",
    "    fig.tight_layout()\n",
    "\n",
    "    return fig, ax, {'slow_time': slow_time_plot, 'distance_to_reflector': distance_to_reflector, 'return_power': return_power,\n",
    "                     'peaks_direct': peaks_direct, 'xcorr_results_stacked': xcorr_results_stacked}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, radargram_data = phase_align_test(n_stack=10, start_time_s=250, duration_s=10, upsampling=1, figsize=(15, 5), vmin=-70, vmax=-10, ylims=(80, 15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radargram_data['xcorr_results_stacked'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(radargram_data['distance_to_reflector'], np.abs(radargram_data['xcorr_results_stacked'][:,100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(np.abs(radargram_data['xcorr_results_stacked']), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radargram_data['peaks_direct'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(radargram_data['xcorr_results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct = [radargram_data['xcorr_results'][x,idx] for idx, x in enumerate(radargram_data['peaks_direct'])]\n",
    "xcorr_aligned = np.array([radargram_data['xcorr_results'][:,idx] * np.exp(-1j * np.angle(direct[idx])) for idx in range(len(radargram_data['slow_time']))])\n",
    "xcorr_aligned = np.transpose(xcorr_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_idxs = np.argmax(np.abs(radargram_data['xcorr_results_stacked']), axis=0)\n",
    "direct = [radargram_data['xcorr_results_stacked'][x,idx] for idx, x in enumerate(peak_idxs)]\n",
    "fig, axs = plt.subplots(3,1, figsize=(15, 10), facecolor='white')\n",
    "\n",
    "axs[0].plot(radargram_data['slow_time'], np.abs(direct))\n",
    "axs[0].set_ylabel('xcorr peak magnitude (linear scale)')\n",
    "\n",
    "axs[1].plot(radargram_data['slow_time'], np.angle(direct))\n",
    "#axs[1].set_ylim(-1.1, -0.9)\n",
    "#axs[1].set_ylim(-0.1, 0.1)\n",
    "axs[1].set_ylabel('xcorr peak phase [rad]')\n",
    "\n",
    "axs[2].plot(radargram_data['slow_time'], peak_idxs)\n",
    "axs[2].set_ylabel('index of xcorr peak')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to normal stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if px4_logs is not None:\n",
    "    # Get UTC time from GPS\n",
    "    df = pd.read_csv(px4_logs + \"sensor_gps_0.csv\")\n",
    "    px4_timestamp_offset_to_utc = (df['time_utc_usec'].at[0] / 1e6) - (df['timestamp'].at[0] / 1e6)\n",
    "\n",
    "    slow_time_unix = slow_time + start_timestamp\n",
    "\n",
    "    def interp_log_to_radar(df, key, interpolation_kind='linear'):\n",
    "        ts = df['timestamp']*1e-6 + px4_timestamp_offset_to_utc\n",
    "\n",
    "        interp_fn = scipy.interpolate.interp1d(ts, df[key], kind=interpolation_kind, bounds_error=False)\n",
    "        return interp_fn(slow_time_unix)\n",
    "\n",
    "    px4_logdata = {'time_s': slow_time}\n",
    "\n",
    "    # Get takeoff/landing times\n",
    "    df = pd.read_csv(px4_logs + \"vehicle_land_detected_0.csv\")\n",
    "    landed = df.loc[df['landed'] == 0]\n",
    "    takeoff, landing = landed['timestamp'].min(), landed['timestamp'].max()\n",
    "    takeoff_radar_timestamp, landing_radar_timestamp = [t*1e-6 + px4_timestamp_offset_to_utc - start_timestamp for t in [takeoff, landing]]\n",
    "    flight_duration = landing_radar_timestamp - takeoff_radar_timestamp\n",
    "    print((takeoff_radar_timestamp, landing_radar_timestamp))\n",
    "\n",
    "    # Distance traveled and local positions\n",
    "    df = pd.read_csv(px4_logs + \"estimator_local_position_0.csv\")\n",
    "    local_x, local_y, local_z = df['x'], df['y'], df['z']\n",
    "    dist_xy_plane = np.cumsum(np.sqrt(np.diff(local_x)**2 + np.diff(local_y)**2))\n",
    "    df['distance_traveled'] = np.concatenate([[0], dist_xy_plane])\n",
    "    px4_logdata['distance_traveled'] = interp_log_to_radar(df, 'distance_traveled')\n",
    "    for k in ['x', 'y', 'z']:\n",
    "        px4_logdata[k] = interp_log_to_radar(df, k)\n",
    "\n",
    "    # Target bearing\n",
    "    df = pd.read_csv(px4_logs + \"position_controller_status_0.csv\")\n",
    "    for k in ['target_bearing', 'nav_roll']:\n",
    "        px4_logdata[k] = interp_log_to_radar(df, k)\n",
    "    \n",
    "    # Mission item index\n",
    "    df = pd.read_csv(px4_logs + \"navigator_mission_item_0.csv\")\n",
    "    px4_logdata['mission_item'] = interp_log_to_radar(df, 'sequence_current', interpolation_kind='previous')\n",
    "\n",
    "    # Load distance sensor data\n",
    "    df_distance_sensor = pd.read_csv(px4_logs + \"distance_sensor_0.csv\")\n",
    "    df_distance_sensor['dist_filt'] = df_distance_sensor['current_distance']\n",
    "    df_distance_sensor['dist_filt'].iloc[df_distance_sensor['dist_filt'] > 120] = None\n",
    "    px4_logdata['dist'] = interp_log_to_radar(df_distance_sensor, 'dist_filt')\n",
    "\n",
    "    df_position = pd.read_csv(px4_logs + \"estimator_global_position_0.csv\")\n",
    "    df_position['alt_rel'] = df_position['alt'] - df_position['alt'].min()\n",
    "    for k in ['lat', 'lon', 'alt_rel']:\n",
    "        px4_logdata[k] = interp_log_to_radar(df_position, k)\n",
    "        \n",
    "    # Vehicle attitude\n",
    "    df_attitude = pd.read_csv(px4_logs + \"vehicle_attitude_0.csv\")\n",
    "    att = R.from_quat(df_attitude[['q[0]', 'q[1]', 'q[2]', 'q[3]']])\n",
    "    att_ypr = att.as_euler('xyz', degrees=True)\n",
    "    df_attitude['yaw'] = att_ypr[:,0]\n",
    "    df_attitude['pitch'] = att_ypr[:,1]\n",
    "    df_attitude['roll'] = att_ypr[:,2]\n",
    "    for k in ['yaw', 'pitch', 'roll']:\n",
    "        px4_logdata[k] = interp_log_to_radar(df_attitude, k)\n",
    "\n",
    "    df_px4 = pd.DataFrame(px4_logdata, index=slow_time)\n",
    "\n",
    "    df_px4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if px4_logs is not None:\n",
    "    fig, ax, plot_data = plot_radargram(n_stack=15, start_time_s=takeoff_radar_timestamp, duration_s=flight_duration, upsampling=3, figsize=(15, 5), vmin=-70, vmax=-40, ylims=(80, 15), x_axis=px4_logdata['distance_traveled']/1000, x_axis_label='Distance [km]')\n",
    "    ax.scatter(px4_logdata['distance_traveled']/1000, df_px4['dist'] / np.sqrt(3.17), c='white', s=1)\n",
    "    #ax.plot(px4_logdata['distance_traveled']/1000, d_interp, c='white')\n",
    "    ax.plot(px4_logdata['distance_traveled']/1000, df_px4['alt_rel'] / np.sqrt(3.17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, plot_data = plot_radargram(n_stack=30, start_time_s=takeoff_radar_timestamp, duration_s=flight_duration, upsampling=1, figsize=(15, 5), vmin=-80, vmax=-40, ylims=(300, 10), x_axis=px4_logdata['distance_traveled']/1000, x_axis_label='Distance [km]')\n",
    "#fig.savefig(prefix + \"_radargram.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, plot_data = plot_radargram(n_stack=40, start_time_s=takeoff_radar_timestamp+60, duration_s=flight_duration-120, upsampling=1, figsize=(15, 5), vmin=-90, vmax=-10, ylims=(250, 10))#, x_axis=px4_logdata['distance_traveled']/1000, x_axis_label='Distance [km]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px4_logdata_df = pd.DataFrame(px4_logdata)\n",
    "\n",
    "mission_idx_diff = np.diff(px4_logdata_df['mission_item'])\n",
    "mission_idx_diff[np.isnan(mission_idx_diff)] = 0\n",
    "\n",
    "mission_segments = np.split(np.array(px4_logdata_df.index), np.squeeze(np.argwhere(mission_idx_diff != 0)))\n",
    "\n",
    "for segment_idx, segment_df_idxs in enumerate(mission_segments):\n",
    "    px4_logdata_segment_df = px4_logdata_df.iloc[segment_df_idxs, :].copy()\n",
    "    segment_distance = px4_logdata_segment_df['distance_traveled'].max() - px4_logdata_segment_df['distance_traveled'].min()\n",
    "    if segment_distance < 300:\n",
    "        continue # skip any short segments\n",
    "\n",
    "    # Optional -- remove first n seconds of the segment -- usually a turn\n",
    "    px4_logdata_segment_df = px4_logdata_segment_df[px4_logdata_segment_df['time_s'] - px4_logdata_segment_df['time_s'].min() > 5]\n",
    "    \n",
    "    start_time = px4_logdata_segment_df['time_s'].min()\n",
    "    duration = px4_logdata_segment_df['time_s'].max() - start_time - 1e-6\n",
    "\n",
    "    # Context plot\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    ax.plot(px4_logdata_df['x'], px4_logdata_df['y'])\n",
    "    ax.plot(px4_logdata_segment_df['x'], px4_logdata_segment_df['y'], c='red')\n",
    "    ax.set_aspect('equal')\n",
    "    ax.scatter([np.array(px4_logdata_segment_df['x'])[0]], [np.array(px4_logdata_segment_df['y'])[0]], c='green', label='Start')\n",
    "    ax.legend()\n",
    "\n",
    "    print(f\"start: {start_time} \\tduration: {duration}\")\n",
    "\n",
    "    # Radargram\n",
    "    fig, ax, _ = plot_radargram(n_stack=40, start_time_s=start_time, duration_s=duration, upsampling=10, figsize=(10*segment_distance/300, 6), vmin=-80, vmax=-40, ylims=(200, 10), x_axis=px4_logdata_df['distance_traveled']/1000, x_axis_label='Distance [km]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "takeoff_radar_timestamp, flight_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, plot_data = plot_radargram(n_stack=30, start_time_s=141, duration_s=150, upsampling=5, figsize=(20, 5), vmin=-80, vmax=-35, ylims=(150, 10), x_axis=px4_logdata['distance_traveled']/1000, x_axis_label='Flight distance from takeoff [km]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "ax.plot(px4_logdata['distance_traveled']/1000, px4_logdata['nav_roll'])\n",
    "ax.set_xlim(1.5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "ax.scatter(df_px4['time_s'], df_px4['dist'] / np.sqrt(3.17), c='blue', s=1)\n",
    "\n",
    "d = df_px4['dist'].to_numpy() / np.sqrt(3.17)\n",
    "\n",
    "laser_delta = np.diff(d) / np.diff(df_px4['time_s'].to_numpy())\n",
    "laser_delta = np.concatenate([laser_delta, [0]])\n",
    "print(np.shape(laser_delta))\n",
    "\n",
    "d[np.isnan(laser_delta)] = np.nan\n",
    "d[np.abs(laser_delta) > 2] = np.nan\n",
    "\n",
    "d[d > 50] = np.nan\n",
    "d[d < 20] = np.nan\n",
    "\n",
    "interp = scipy.interpolate.interp1d((df_px4['time_s'].to_numpy())[~np.isnan(d)], d[~np.isnan(d)], kind='cubic', bounds_error=False)\n",
    "d_interp = interp(df_px4['time_s'])\n",
    "\n",
    "ax.scatter(df_px4['time_s'], d, c='red', s=1)\n",
    "ax.plot(df_px4['time_s'], d_interp, c='orange')\n",
    "\n",
    "#ax.scatter((df_px4['time_s'].to_numpy())[:-1], np.diff(d) / np.diff(df_px4['time_s'].to_numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, plot_data = plot_radargram(n_stack=15, start_time_s=350, duration_s=100, upsampling=10, figsize=(15, 5), vmin=-65, vmax=-45, ylims=(60, 15))\n",
    "fig, ax, plot_data = plot_radargram(n_stack=15, start_time_s=350, duration_s=100, upsampling=10, figsize=(15, 5), vmin=-65, vmax=-45, ylims=(35, -10), surface_dist=d_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin(np.abs(plot_data['distance_to_reflector'])), np.argmin(np.abs(plot_data['distance_to_reflector'] - 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ret_pwr[318:398,1000]\n",
    "peaks, _ = scipy.signal.find_peaks(s, prominence=(10, None), height=-60)\n",
    "plt.plot(s)\n",
    "plt.scatter(peaks, s[peaks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_pwr = plot_data['return_power']\n",
    "peak_idxs = np.zeros((np.shape(ret_pwr)[1],), dtype=int) * np.nan\n",
    "\n",
    "peak_dists = np.zeros(peak_idxs.shape) * np.nan\n",
    "\n",
    "for idx in range(ret_pwr.shape[1]):\n",
    "    peaks, _ = scipy.signal.find_peaks(ret_pwr[318:398, idx], prominence=(10, None), height=-60)\n",
    "    if len(peaks) > 0:\n",
    "        peak_idxs[idx] = peaks[0] + 318\n",
    "        peak_dists[idx] = plot_data['distance_to_reflector'][peaks[0] + 318]\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(peak_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_dists_filt = scipy.signal.medfilt(peak_dists, 11)\n",
    "plt.plot(peak_dists_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, plot_data = plot_radargram(n_stack=30, start_time_s=100, duration_s=700, upsampling=5, figsize=(20, 5), vmin=-80, vmax=-40, ylims=(130, 10), x_axis=px4_logdata['distance_traveled']/1000, x_axis_label='Flight distance from takeoff [km]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump interpolated data to a pickle file\n",
    "\n",
    "px4_interp = {'time_s': plot_data['slow_time']}\n",
    "\n",
    "for k in df_px4:\n",
    "    interp = scipy.interpolate.interp1d(df_px4['time_s'], df_px4[k], kind='linear', bounds_error=False)\n",
    "    px4_interp[k] = interp(plot_data['slow_time'])\n",
    "\n",
    "df_px4_interp = pd.DataFrame(px4_interp)\n",
    "\n",
    "start_idx, end_idx = np.argmin(np.abs(plot_data['distance_to_reflector'] - 10)), np.argmin(np.abs(plot_data['distance_to_reflector'] - 200))\n",
    "\n",
    "data = {\n",
    "    'return_power': plot_data['return_power'][start_idx:end_idx, :], # (2241 by 2666) where 2241 is the number of range bins and 2666 is the number of timesteps\n",
    "    'slow_time': plot_data['slow_time'], # 2666 -- relative timestamps in seconds\n",
    "    'distance_to_reflector': plot_data['distance_to_reflector'][start_idx:end_idx], # 2441 -- one-way distance to a reflector assuming propagation velocity in ice (speed of light / sqrt(3.17))\n",
    "    'lat': df_px4_interp['lat'].to_numpy(), # latitude\n",
    "    'lon': df_px4_interp['lon'].to_numpy(), # longitude\n",
    "    'alt_rel': df_px4_interp['alt_rel'].to_numpy(),\n",
    "    'dist': df_px4_interp['dist'].to_numpy()\n",
    "}\n",
    "\n",
    "with open('20230315_flight3.pickle', 'wb') as f:\n",
    "   pickle.dump(data, f)\n",
    "\n",
    "# Code to read:\n",
    "# import pickle\n",
    "# import numpy as np\n",
    "\n",
    "# with open('20220901_flight2_full.pickle', 'rb') as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "# for k in data:\n",
    "#     print(f\"[{k}] shape: {np.shape(data[k])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rg]",
   "language": "python",
   "name": "conda-env-rg-filprofile"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "cb76c480065e4e286b6e0fa74c4810c787aa0b031f4beccb07cdff25e17fa130"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
